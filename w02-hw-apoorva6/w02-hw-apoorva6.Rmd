---
title: "Week 2 - Homework"
author: "STAT 420, Summer 2018, Apoorva, apoorva6"
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---


## Exercise 1 (Using `lm`)

For this exercise we will use the `cats` dataset from the `MASS` package. 

**(a)** Suppose we would like to understand the size of a cat's heart based on the body weight of a cat. Fit a simple linear model in `R` that accomplishes this task. Store the results in a variable called `cat_model`. Output the result of calling `summary()` on `cat_model`.

```{r}
cats <- MASS :: cats
cat_model <- lm(Hwt ~ Bwt, data= cats)
summary(cat_model)
```

**(b)** Output only the estimated regression coefficients. Interpret $\hat{\beta_0}$ and $\beta_1$ in the *context of the problem*.

```{r}
cat_model$coefficients
beta_0_hat <- cat_model$coefficients[1]
beta_0_hat
beta_1_hat <- cat_model$coefficients[2]
beta_1_hat

# OR 
# beta_0_hat <- summary(cat_model)$coefficients[1,1]
# beta_1_hat <- summary(cat_model)$coefficients[2,1]
```


**(c)** Use your model to predict the heart weight of a cat that weights **2.7** kg. Do you feel confident in this prediction? Briefly explain.

```{r}
pred1 <- summary(cat_model)$coefficients[1,1] +(summary(cat_model)$coefficients[2,1]*2.7)
pred1
```

This prediction is more reliable as the prediction is an intrapolation of the data values already available.
Thus we can confidently predict it.


**(d)** Use your model to predict the heart weight of a cat that weights **4.4** kg. Do you feel confident in this prediction? Briefly explain.

```{r}
pred2 <- summary(cat_model)$coefficients[1,1] +(summary(cat_model)$coefficients[2,1]*4.4)
pred2
```

This prediction is less reliable as we are predicting the value of  heart rate as a result of extraploation from the data. Thus we cannot be very sure of the prediction.

**(e)** Create a scatterplot of the data and add the fitted regression line. Make sure your plot is well labeled and is somewhat visually appealing.

```{r}
plot(Hwt ~ Bwt, data = cats,
     xlab = "Body weight(in kgs)",
     ylab = "Heart weight(in kgs)",
     main = "Body weight Vs Heart weight of cats",
     pch  = 20,
     cex  = 1,
     col  = "blue")
abline(cat_model, lwd = 3, col = "darkorange")
```


**(f)** Report the value of $R^2$ for the model. Do so directly. Do not simply copy and paste the value from the full output in the console after running `summary()` in part **(a)**.

```{r}
rsquared <- summary(cat_model)$r.squared
rsquared
```


## Exercise 2 (Writing Functions)

**(a)** Write a function called `get_sd_est` that calculates an estimate of $\sigma$ in one of two ways depending on input to the function. The function should take three arguments as input:

- `fitted_vals` - A vector of fitted values from a model
- `actual_vals` - A vector of the true values of the response
- `mle` - A logical (`TRUE` / `FALSE`) variable which defaults to `FALSE`

The function should return a single value:

- $s_e$ if `mle` is set to `FALSE`.
- $\hat{\sigma}$ if `mle` is set to `TRUE`.

```{r}
y <- cats$Hwt
yhat <- summary(cat_model)$coefficients[1,1] + (summary(cat_model)$coefficients[2,1]*cats$Bwt)
e <- y- yhat
len <- length(e)
  
get_sd_est <- function(fitted_vals=yhat, actual_vals=y, mle = FALSE)
{
  se <-  sqrt (sum(e^2)/(len-2))
  sigmahat <- sqrt (sum(e^2)/(len))
  ifelse (mle  == FALSE, se ,sigmahat)
}
```


**(b)** Run the function `get_sd_est` on the residuals from the model in Exercise 1, with `mle` set to `FALSE`. Explain the resulting estimate in the context of the model.

```{r}
get_sd_est(yhat,y,FALSE)
```
This particular code gives the value of Se which is an "estimate" of the square root of variance(sd) or Residual standard error of the model parameter using the **Least Squares method**

**(c)** Run the function `get_sd_est` on the residuals from the model in Exercise 1, with `mle` set to `TRUE`. Explain the resulting estimate in the context of the model. Note that we are trying to estimate the same parameter as in part **(b)**.

```{r}
get_sd_est(yhat,y,TRUE)
```
This piece of code returns the estimated value of the standard deviation through **Maximum likelihood method**.

**(d)** To check your work, output `summary(cat_model)$sigma`. It should match at least one of **(b)** or **(c)**.

```{r}
summary(cat_model)$sigma
```



## Exercise 3 (Simulating SLR)

Consider the model

\[
Y_i = 5 + -3 x_i + \epsilon_i
\]

with 

\[
\epsilon_i \sim N(\mu = 0, \sigma^2 = 10.24)
\]

where $\beta_0 = 5$ and $\beta_1 = -3$.

This exercise relies heavily on generating random observations. To make this reproducible we will set a seed for the randomization. Alter the following code to make `birthday` store your birthday in the format: `yyyymmdd`

```{r}
birthday = 19920720
set.seed(birthday)
```

**(a)** Use `R` to simulate `n = 25` observations from the above model. For the remainder of this exercise, use the following "known" values of $x$.

```{r}
num_obs = 25
beta_0  = 5
beta_1  = -3
sigma   = sqrt(10.24)
x = runif(n = 25, 0, 10)
```


**(b)** Fit a model to your simulated data. Report the estimated coefficients. Are they close to what you would expect? Briefly explain.

```{r}
num_obs = 25
beta_0  = 5
beta_1  = -3
sigma   = sqrt(10.24)
x = runif(n = 25, 0, 10)

sim_slr = function(x, beta_0 = 5, beta_1 = -3, sigma = 3.2) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

sim_data = sim_slr(x = x, beta_0 = 5, beta_1 = -3, sigma = 3.2)

ft_data = lm(response ~ predictor, data = sim_data)
coef(ft_data)
```

The output of our simulation is almost very accurate with just a small amount of error.
True values(known):
  $\beta_1 = -3$ and 
  $\beta_0 = 5$
As we can see, the predictions are very close to the actual values.

**(c)** Plot the data you simulated in part **(a)**. Add the regression line from part **(b)** as well as the line for the true model. Hint: Keep all plotting commands in the same chunk.

```{r}
plot(response ~ predictor, data = sim_data,
     xlab = "Simulated Predictor Variable",
     ylab = "Simulated Response Variable",
     main = "Simulated Regression Data",
     pch  = 20,
     cex  = 2,
     col  = "grey")
abline(ft_data, lwd = 3, lty = 1, col = "darkorange")
abline(beta_0, beta_1, lwd = 3, lty = 2, col = "dodgerblue")
legend("topright", c("Estimate", "Truth"), lty = c(1, 2), lwd = 2,
       col = c("darkorange", "dodgerblue"))

```


**(d)** Use `R` to repeat the process of simulating `n = 25` observations from the above model $1500$ times. Each time fit a SLR model to the data and store the value of $\hat{\beta_1}$ in a variable called `beta_hat_1`. Some hints:

```{r}

beta_hat_1 <- as.vector(rep(0,1500))
for (i in 1:1500)
{
  sim_slr = function(x, beta_0 = 5, beta_1 = -3, sigma = 3.2) {
        n = length(x)
        epsilon = rnorm(n, mean = 0, sd = sigma)
        y = beta_0 + beta_1 * x + epsilon
        data.frame(predictor = x, response = y)}
  sim_temp <- sim_slr(x = x, beta_0 = 5, beta_1 = -3, sigma = 3.2)
  slr_temp <-  lm(response ~ predictor,data = sim_temp)
  coef <-  coef(slr_temp)[2]
  beta_hat_1[i] <- coef
  i <- i+1
}

```

**(e)** Report the mean and standard deviation of `beta_hat_1`. Do either of these look familiar?
```{r}
mean_beta_hat1 <- mean(beta_hat_1)
mean_beta_hat1
sd_beta_hat1 <- sd(beta_hat_1)
sd_beta_hat1
```
The mean value of the slope obtained from running multiple combinations(simulations) of the response values is very close to the actual mean value
considered for the simluation
Actual model slope considered = -3
Average predicted slope of the 1500 simulations ~ -3

**(f)** Plot a histogram of `beta_hat_1`. Comment on the shape of this histogram.

```{r}
histogram_beta_hat1 = hist(beta_hat_1, breaks = 50,
                           main = "Histogram of slope estimate",
                           xlab = " Estimate of slope", col = "grey")
box(col="grey")

```

The histogram follows a normal distribution with few odd spikes at some points of the slope. But for every new simulation the distribution still remains a normal distribution.


## Exercise 4 (Be a Skeptic)

Consider the model

\[
Y_i = 3 + 0 \cdot x_i + \epsilon_i
\]

with

\[
\epsilon_i \sim N(\mu = 0, \sigma^2 = 4)
\]

where $\beta_0 = 3$ and $\beta_1 = 0$.

```{r}
birthday = 19920720
set.seed(birthday)
```

**(a)** Use `R` to repeat the process of simulating `n = 75` observations from the above model $2500$ times. For the remainder of this exercise, use the following "known" values of $x$.

```{r}
x = runif(n = 75, 0, 10)
```

Each time fit a SLR model to the data and store the value of $\hat{\beta_1}$ in a variable called `beta_hat_1`. 

```{r}
sim_slr = function(x, beta_0 = 3, beta_1 = 0, sigma = 2) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

options(scipen = 999)
beta_hat_1 <- as.vector(rep(0,2500))
for (i in 1:2500)
{
  sim_temp <- sim_slr(x = x, beta_0 = 3, beta_1 = 0, sigma = 2)
  slr_temp <-  lm(response ~ predictor,data = sim_temp)
  coef <-  coef(slr_temp)[2]
  beta_hat_1[i] <- coef
  i <- i+1
}
```


**(b)** Plot a histogram of `beta_hat_1`. Comment on the shape of this histogram.
```{r}
histogram_beta_hat1 = hist(beta_hat_1, breaks = 50,
                           main = "Histogram of slope estimate",
                           xlab = " Estimate of slope", col = "grey")
box(col="grey")

```

The histogram follows a normal distribution with few odd spikes at some points of the slope. But for every new simulation the distribution still remains a normal distribution.


**(c)** Import the data in [`skeptic.csv`](skeptic.csv) and fit a SLR model. The variable names in `skeptic.csv` follow the same convention as those returned by `sim_slr()`. Extract the fitted coefficient for $\beta_1$.

```{r}
skeptic <- read.csv("skeptic.csv")
slr_skeptic <- lm(response~predictor, data =skeptic)
beta_1hat_skeptic <- coef(slr_skeptic)[2]
beta_1hat_skeptic
```

**(d)** Re-plot the histogram from **(b)**. Now add a vertical red line at the value of $\hat{\beta_1}$ in part **(c)**. 

```{r}
histogram_value_comp = hist(beta_hat_1, breaks = 50,
                           main = "Histogram of slope estimate",
                           xlab = " Estimate of slope", col = "grey")
box(col="grey")
abline(v = beta_1hat_skeptic, col = "red")
```

**(e)** Your value of $\hat{\beta_1}$ in **(c)** should be negative. What proportion of the `beta_hat_1` values is smaller than your $\hat{\beta_1}$? Return this proportion, as well as this proportion multiplied by `2`.

```{r}
prop <- length(beta_hat_1[beta_hat_1 < beta_1hat_skeptic ]) / length(beta_hat_1)
prop
Prop_mul_2 <- prop *2
Prop_mul_2
```

**(f)** Based on your histogram and part **(e)**, do you think the [`skeptic.csv`](skeptic.csv) data could have been generated by the model given above? Briefly explain.

The skeptic dataset can be generated by the model implemented in the first part of the question as their estimated values are very close to their actual values.(Also because they use the same axis and scale)


## Exercise 5 (Comparing Models)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. 

For simplicity, we will perform some data cleaning before proceeding.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

We have:

- Loaded the data from the package
- Subset the data to relevant variables
    - This is not really necessary (or perhaps a good idea) but it makes the next step easier
- Given variables useful names
- Removed any observation with missing values
    - This should be given much more thought in practice

For this exercise we will define the "Root Mean Square Error" of a model as

\[
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2}.
\]

**(a)** Fit three SLR models, each with "ozone" as the response. For the predictor, use "wind speed," "humidity percentage," and "temperature" respectively. For each, calculate $\text{RMSE}$ and $R^2$. Arrange the results in a markdown table, with a row for each model. Suggestion: Create a data frame that stores the results, then investigate the `kable()` function from the `knitr` package.

```{r}

data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]

slr1 <-  lm(ozone~wind, data = Ozone)
slr2  <-  lm(ozone~humidity, data = Ozone)
slr3 <-  lm(ozone~temp, data = Ozone)

pred1 <- predict(slr1)
e1 <- Ozone$ozone - pred1
rmse1 <- sqrt(mean(e1^2))
rsquared1 <- summary(slr1)$r.squared

pred2 <- predict(slr2)
e2 <- Ozone$ozone - pred2
rmse2 <- sqrt(mean(e2^2))
rsquared2 <- summary(slr2)$r.squared

pred3 <- predict(slr3)
e3 <- Ozone$ozone - pred3
rmse3 <- sqrt(mean(e3^2))
rsquared3 <- summary(slr3)$r.squared

RMSE <- c(rmse1,rmse2,rmse3)
rsquared <- c(rsquared1,rsquared2,rsquared3)

final<- data.frame(RMSE,rsquared)
rownames(final) <- c("wind", "humidity", "temp")
library(knitr)
kable(final, format = "markdown")

```


**(b)** Based on the results, which of the three predictors used is most helpful for predicting ozone? Briefly explain.

 Of the the three predictors- wind, humidity and temperature, "temperature" looks like a good predictor as it has the highest r-squared among the three, and also lowest root mean square error.




